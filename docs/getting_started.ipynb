{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started\n",
    "Kooplearn is a machine learning library designed for a specific purpose: implement state-of-the-art algorithmes to learn Koopman/Transfer operators of dynamical systems from data. For a user-friendly introduction to the operatorial perspective on dynamical systems check out [this blog post [TODO]](). \n",
    "\n",
    "In this article we will go through a typical training and inference pipeline in `kooplearn`, experimenting with the _noisy logistic map_, a one-dimensional dynamical system defined by the relation\n",
    "\n",
    "$$\n",
    "    x_{t + 1} = (4x_{t}(1 - x_{t}) + \\xi_{t}) \\mod 1.\n",
    "$$\n",
    "\n",
    "Here $\\xi_{t}$ is just a noise term with density $\\propto \\cos^{N}(x)$, $N$ being an even integer and $x \\in [-0.5, 0.5]$. {footcite:t}`Kostic2022` reported a full characterization of the transfer operator of the noisy logistic map. In particular, the transfer operator has rank $N + 1$, it is _non-normal_, and its eigenvalues and eigenfunctions can be computed with arbitrary precision. In `kooplearn` we provide an implementation of the noisy logistic map in {class}`kooplearn.datasets.LogisticMap`.\n",
    "\n",
    "## Generating and splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kooplearn.datasets import LogisticMap\n",
    "\n",
    "# Defining the number of samples for each data split\n",
    "train_samples = 1000 \n",
    "val_samples = 200\n",
    "test_samples = 1000\n",
    "\n",
    "logmap = LogisticMap(N = 20, rng_seed = 0) # Setting the rng_seed for reproducibility\n",
    "\n",
    "initial_condition = 0.5 # Setting the initial condition x_0 to start sampling the map\n",
    "\n",
    "datasets = {\n",
    "    'train': logmap.sample(initial_condition, train_samples),\n",
    "    'val': logmap.sample(initial_condition, val_samples),\n",
    "    'test': logmap.sample(initial_condition, test_samples)\n",
    "}\n",
    "\n",
    "for split, ds in datasets.items():\n",
    "    print(f\"{split.capitalize()} split has shape {ds.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, we have a numpy array of shape `(split_samples + 1, 1)` for each split, stored in the `datasets` dictionary. Notice that even if we requested `split_samples` the `sample` function returned one extra sample. This is no accident, the \"extra\" sample is actually the initial condition, and calling `logistic.sample` we have appended `split_samples` new fresh points to it.\n",
    "\n",
    "## Learning the transfer operator on a dictionary of functions\n",
    "\n",
    "We recall that the transfer operator $\\mathcal{T}$ is a mathematical object that maps any function $f$ to its expected value after one step of the dynamics:\n",
    "\n",
    "$$\n",
    "(\\mathcal{T}f)(x) := \\mathbb{E}[f(X_t + 1) | X_t = x].\n",
    "$$\n",
    "\n",
    "A popular class of methods to learn $\\mathcal{T}$ from data follows from the observation that the action of $\\mathcal{T}$ on the span of a _finite_ number of functions $(\\phi_{i})_{i = 1}^{d}$ is described by a $d\\times d$ matrix, which can be learned from data via standard regression algorithms. If the chosen set of functions $(\\phi_{i})_{i = 1}^{d}$ is rich enough, we should have a decent approximation of the transfer operator. We refer to {footcite:t}`Kostic2022` for a mathematically rigorous exposition of these topics. \n",
    "\n",
    "This strategy is implemented in the {class}`kooplearn.models.ExtendedDMD` model, which requires as input the functions $(\\phi_{i})_{i = 1}^{d}$ specified as a feature map $x \\mapsto  (\\phi_{i}(x))_{i = 1}^{d}$. The choiche of feature map is highly problem dependent and `kooplearn` exposes an abstract base class {class}`kooplearn.abc.FeatureMap` as a blueprint. For the noisy logistic map a sensible option is a set of orthogonal polynomials, such as the [Chebyshev polynomials of the first kind](https://en.wikipedia.org/wiki/Chebyshev_polynomials). Let's implement that by subclassing {class}`kooplearn.abc.FeatureMap`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.special\n",
    "from kooplearn.abc import FeatureMap\n",
    "\n",
    "class ChebyshevPoly(FeatureMap):\n",
    "    def __init__(self, max_order: int = 10):\n",
    "        self.max_order = max_order # Will take polynomials up to order max_order (excluded)\n",
    "    \n",
    "    def __call__(self, data: np.ndarray):\n",
    "        x = 2 * data - 1 # Transforms the input data defined on [0, 1] to the interval [-1, 1] over which the Chebyshev polynomials are defined.\n",
    "        phi = np.concatenate([scipy.special.eval_chebyt(n, x) for n in range(self.max_order)], axis=-1)\n",
    "        return phi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's instantiate the feature map and test how it acts on one of our data splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The featurized train split has shape (1001, 4)\n",
      "The featurized val split has shape (201, 4)\n",
      "The featurized test split has shape (1001, 4)\n"
     ]
    }
   ],
   "source": [
    "feature_map = ChebyshevPoly(max_order = 4)\n",
    "\n",
    "for split, ds in datasets.items():\n",
    "    print(f\"The featurized {split} split has shape {feature_map(ds).shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{footbibliography}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kooplearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
