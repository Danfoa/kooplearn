{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T22:33:22.873121Z",
     "start_time": "2024-03-14T22:33:22.824940Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T22:33:27.850959Z",
     "start_time": "2024-03-14T22:33:22.938243Z"
    }
   },
   "source": [
    "import importlib\n",
    "\n",
    "for module in ['kooplearn', 'datasets', 'matplotlib', 'ml-confs']: # !! Add here any additional module that you need to install on top of kooplearn\n",
    "    try:\n",
    "        importlib.import_module(module)\n",
    "    except ImportError:\n",
    "        if module == 'kooplearn':\n",
    "            module = 'kooplearn[full]'\n",
    "        %pip install -q {module}"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T22:33:28.481311Z",
     "start_time": "2024-03-14T22:33:27.852574Z"
    }
   },
   "source": [
    "import data_pipeline\n",
    "import ml_confs\n",
    "from datasets import load_from_disk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_pipeline.main() # Run data download and preprocessing\n",
    "configs = ml_confs.from_file('configs.yaml') # Load configs\n",
    "ordered_MNIST = load_from_disk('__data__') # Load dataset (torch)\n",
    "device = 'cpu' #Â Set default device\n",
    "\n",
    "fig, ax = plt.subplots(3, configs.classes, figsize=(configs.classes, 3))\n",
    "for j, split in enumerate(['train', 'test', 'validation']):\n",
    "    print(f'{split} ({len(ordered_MNIST[split])}) example: {ordered_MNIST[split][\"label\"][:configs.classes]}')\n",
    "    for i in range(configs.classes):\n",
    "        data = ordered_MNIST['train'][configs.classes*j + i]\n",
    "        ax[j, i].imshow(data['image'], cmap='gray')\n",
    "        ax[j, i].set_title(data['label'].item())\n",
    "        ax[j, i].axis('off')\n",
    "fig.tight_layout()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up a validation scheme\n",
    "The validation of each model will be performed as follows: starting from a test image of the digit $c$, we will predict the next image by calling `model.predict`. The prediction should be an MNIST-alike image of the digit $c+1$ (modulo `configs.classes`). We will feed this prediction to a very strong MNIST classifier, and evaluate how its accuracy degrades over time.\n",
    "\n",
    "### Defining the _oracle_ classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T22:33:28.505286Z",
     "start_time": "2024-03-14T22:33:28.482197Z"
    }
   },
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "#Setting up the architecture\n",
    "class CNNEncoder(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNNEncoder, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              \n",
    "                out_channels=16,            \n",
    "                kernel_size=5,              \n",
    "                stride=1,                   \n",
    "                padding=2,                  \n",
    "            ),                              \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(kernel_size=2),    \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(16, 32, 5, 1, 2),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(2),                \n",
    "        )\n",
    "        # Fully connected layer, output num_classes classes\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(32 * 7 * 7, num_classes)\n",
    "        )  \n",
    "        torch.nn.init.orthogonal_(self.out[0].weight)      \n",
    "    \n",
    "    def forward(self, X):\n",
    "        if X.dim() == 3:\n",
    "            X = X.unsqueeze(1) # Add a channel dimension if needed\n",
    "        X = self.conv1(X)\n",
    "        X = self.conv2(X)\n",
    "        # Flatten the output of conv2\n",
    "        X = X.view(X.size(0), -1)       \n",
    "        output = self.out(X)\n",
    "        return output"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wrap the oracle classifier around a `kooplearn.abc.TrainableFeatureMap`. This will allow us to easily replicate the setting of Kostic et al. 2022, and it is pedagogical to show how `kooplearn` can be extended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T22:33:28.532704Z",
     "start_time": "2024-03-14T22:33:28.506649Z"
    }
   },
   "source": [
    "from kooplearn.abc import TrainableFeatureMap\n",
    "\n",
    "import os\n",
    "from typing import Optional, NamedTuple\n",
    "import logging\n",
    "\n",
    "import lightning\n",
    "import numpy as np\n",
    "\n",
    "class Metrics(NamedTuple):\n",
    "    train_acc: list[float]\n",
    "    train_steps: list[float]\n",
    "    val_acc: list[float]\n",
    "    val_steps: list[float]\n",
    "\n",
    "\n",
    "#Following kooplearn implementations, we define a Pytorch Lightning module and then wrap it in a TrainableFeatureMap\n",
    "class ClassifierModule(lightning.LightningModule):\n",
    "    def __init__(self, num_classes: int, learning_rate: float):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.encoder = CNNEncoder(num_classes=num_classes)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    def on_fit_start(self):\n",
    "        self.metrics = Metrics([], [], [], [])\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr = self.learning_rate)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, labels = batch['image'], batch['label']\n",
    "        output = self.encoder(images)               \n",
    "        loss = self.loss_fn(output, labels)\n",
    "        with torch.no_grad():\n",
    "            pred_labels = output.argmax(dim=1)\n",
    "            accuracy = (pred_labels == labels).float().mean()\n",
    "        \n",
    "        #Log metrics\n",
    "        self.metrics.train_acc.append(accuracy.item())\n",
    "        self.metrics.train_steps.append(self.global_step)\n",
    "        \n",
    "        return {'loss': loss, 'train/accuracy': accuracy}\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, labels = batch['image'], batch['label']\n",
    "        output = self.encoder(images)  \n",
    "        pred_labels = output.argmax(dim=1)\n",
    "        accuracy = (pred_labels == labels).float().mean() # Scalar\n",
    "\n",
    "        self.metrics.val_acc.append(accuracy.item())\n",
    "        self.metrics.val_steps.append(self.global_step)\n",
    "\n",
    "        return {'val/accuracy': accuracy}\n",
    "    \n",
    "class ClassifierFeatureMap(TrainableFeatureMap):\n",
    "    def __init__(\n",
    "                self, \n",
    "                num_classes: int,\n",
    "                learning_rate: float,\n",
    "                trainer: lightning.Trainer,\n",
    "                seed: Optional[int] = None  \n",
    "                ):\n",
    "        #Set rng seed\n",
    "        lightning.seed_everything(seed)\n",
    "        self.seed = seed\n",
    "        self.lightning_module = ClassifierModule(num_classes, learning_rate)\n",
    "        \n",
    "        #Init trainer\n",
    "        self.lightning_trainer = trainer\n",
    "        self._is_fitted = False\n",
    "        \n",
    "    @property\n",
    "    def is_fitted(self) -> bool:\n",
    "        return self._is_fitted\n",
    "    \n",
    "    @property\n",
    "    def lookback_len(self) -> int:\n",
    "        return 1 #Hardcoding it here, as we are not using lookback windows\n",
    "    \n",
    "    #Not tested\n",
    "    def save(self, path: os.PathLike):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    #Not tested\n",
    "    @classmethod\n",
    "    def load(cls, path: os.PathLike):\n",
    "       raise NotImplementedError\n",
    "\n",
    "    def fit(self, **trainer_fit_kwargs: dict):\n",
    "        if 'model' in trainer_fit_kwargs:\n",
    "            logging.warn(f\"The 'model' keyword should not be specified in trainer_fit_kwargs. The provided model '{trainer_fit_kwargs['model']}' is ignored.\")\n",
    "            trainer_fit_kwargs = trainer_fit_kwargs.copy()\n",
    "            del trainer_fit_kwargs['model']\n",
    "        self.lightning_trainer.fit(model=self.lightning_module, **trainer_fit_kwargs)\n",
    "        self._is_fitted = True\n",
    "\n",
    "    def __call__(self, X: np.ndarray) -> np.ndarray:\n",
    "        X = torch.from_numpy(X.copy(order=\"C\")).float()\n",
    "        self.lightning_module.eval()\n",
    "        with torch.no_grad():\n",
    "            embedded_X = self.lightning_module.encoder(\n",
    "                X.to(self.lightning_module.device)\n",
    "            )\n",
    "            embedded_X = embedded_X.detach().cpu().numpy()\n",
    "        return embedded_X"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train `ClassifierFeatureMap` on our `ordered_MNIST` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T22:33:35.371491Z",
     "start_time": "2024-03-14T22:33:28.533595Z"
    }
   },
   "source": [
    "from torch.utils.data import DataLoader\n",
    "oracle_train_dl = DataLoader(ordered_MNIST['train'], batch_size=configs.batch_size, shuffle=True)\n",
    "oracle_val_dl = DataLoader(ordered_MNIST['validation'], batch_size=len(ordered_MNIST['validation']), shuffle=False)\n",
    "        \n",
    "trainer_kwargs = {\n",
    "    'accelerator': device,\n",
    "    'max_epochs': 20,\n",
    "    'log_every_n_steps': 2,\n",
    "    'enable_progress_bar': False,\n",
    "    'devices': 1\n",
    "}\n",
    "\n",
    "trainer = lightning.Trainer(**trainer_kwargs)\n",
    "\n",
    "oracle = ClassifierFeatureMap(\n",
    "    configs.classes,\n",
    "    1e-2,\n",
    "    trainer, \n",
    "    seed=configs.rng_seed\n",
    ")\n",
    "\n",
    "oracle.fit(train_dataloaders=oracle_train_dl, val_dataloaders=oracle_val_dl)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T22:33:35.514097Z",
     "start_time": "2024-03-14T22:33:35.372422Z"
    }
   },
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(oracle.lightning_module.metrics.train_steps, oracle.lightning_module.metrics.train_acc, label='Train')\n",
    "ax.plot(oracle.lightning_module.metrics.val_steps, oracle.lightning_module.metrics.val_acc, label='Validation')\n",
    "ax.set_xlabel('Global step')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.legend(frameon=False, loc='lower right')\n",
    "ax.margins(x=0)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T22:33:36.018710Z",
     "start_time": "2024-03-14T22:33:35.514942Z"
    }
   },
   "source": [
    "from kooplearn.models import Linear, Nonlinear\n",
    "from kooplearn.models.feature_maps.nn import NNFeatureMap\n",
    "from kooplearn.data import traj_to_contexts\n",
    "\n",
    "train_data = traj_to_contexts(ordered_MNIST['train']['image'], backend='numpy')\n",
    "val_data = traj_to_contexts(ordered_MNIST['validation']['image'], backend='numpy')\n",
    "test_data = traj_to_contexts(ordered_MNIST['test']['image'], backend='numpy')\n",
    "test_labels = np.take(ordered_MNIST['test']['label'], np.squeeze(test_data.idx_map.lookback(1))).detach().cpu().numpy()\n",
    "transfer_operator_models = {}"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T22:33:36.135206Z",
     "start_time": "2024-03-14T22:33:36.019683Z"
    }
   },
   "source": [
    "linear_model = Linear(reduced_rank = configs.reduced_rank, rank=configs.classes).fit(train_data)\n",
    "transfer_operator_models['Linear'] = linear_model"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier features (as in Sec. 6 of Kostic et al. 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T22:33:36.323409Z",
     "start_time": "2024-03-14T22:33:36.136868Z"
    }
   },
   "source": [
    "classifier_model = Nonlinear(oracle, reduced_rank=False, rank=configs.classes).fit(train_data)\n",
    "transfer_operator_models['Classifier_Baseline'] = classifier_model"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader for `kooplearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T22:33:36.351101Z",
     "start_time": "2024-03-14T22:33:36.325435Z"
    },
    "collapsed": false
   },
   "source": [
    "from kooplearn.nn.data import collate_context_dataset\n",
    "\n",
    "train_dl = DataLoader(train_data, batch_size = configs.batch_size, shuffle=True, collate_fn=collate_context_dataset)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DPNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T22:33:53.315597Z",
     "start_time": "2024-03-14T22:33:36.352059Z"
    },
    "collapsed": false
   },
   "source": [
    "from kooplearn.nn import DPLoss, VAMPLoss\n",
    "trainer_kwargs = {\n",
    "    'accelerator': device,\n",
    "    'devices': 1,\n",
    "    'max_epochs': configs.max_epochs,  \n",
    "    'log_every_n_steps': 3,\n",
    "    'enable_model_summary': False\n",
    "}\n",
    "\n",
    "\n",
    "feature_maps = {\n",
    "    'DPNets_Relaxed': {\n",
    "        'loss_fn': DPLoss,\n",
    "        'loss_kwargs': {'relaxed': True, 'metric_deformation': 1, 'center_covariances': False}\n",
    "    },\n",
    "    'DPNets': {\n",
    "        'loss_fn': DPLoss,\n",
    "        'loss_kwargs': {'relaxed': False, 'metric_deformation': 1, 'center_covariances': False}\n",
    "    },\n",
    "    'VAMPNets': {\n",
    "        'loss_fn': VAMPLoss,\n",
    "        'loss_kwargs': {'schatten_norm': 2, 'center_covariances': False}\n",
    "    },\n",
    "}\n",
    "\n",
    "for fname, fdict in feature_maps.items():\n",
    "    print(f\"Fitting {fname.replace('_', ' ')}\")\n",
    "    trainer = lightning.Trainer(**trainer_kwargs)\n",
    "    #Defining the model\n",
    "    feature_map = NNFeatureMap(\n",
    "        CNNEncoder,\n",
    "        fdict['loss_fn'],\n",
    "        torch.optim.Adam,\n",
    "        trainer,\n",
    "        encoder_kwargs={'num_classes': configs.classes},\n",
    "        loss_kwargs=fdict['loss_kwargs'],\n",
    "        optimizer_kwargs={'lr': 9e-4},\n",
    "        seed=configs.rng_seed\n",
    "    )\n",
    "    feature_map.fit(train_dl)\n",
    "    nn_model = Nonlinear(feature_map, reduced_rank = configs.reduced_rank, rank=configs.classes).fit(train_data)\n",
    "    transfer_operator_models[fname] = nn_model"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Dynamic AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T22:33:53.342836Z",
     "start_time": "2024-03-14T22:33:53.316589Z"
    },
    "collapsed": false
   },
   "source": [
    "#A decoder which is specular to CNNEncoder, starting with a fully connected layer and then reshaping the output to a 2D image\n",
    "class CNNDecoder(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CNNDecoder, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(num_classes, 32 * 7 * 7)\n",
    "        )\n",
    "        \n",
    "        self.conv1 = nn.Sequential(  \n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.ReLU(),   \n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=32,              \n",
    "                out_channels=16,            \n",
    "                kernel_size=5,              \n",
    "                stride=1,                   \n",
    "                padding=2,                  \n",
    "            )                            \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.ReLU(),                               \n",
    "            nn.ConvTranspose2d(16, 1, 5, 1, 2)                \n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = x.view(x.size(0), 32, 7, 7)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        #Remove the channel dimension\n",
    "        x = x.squeeze(1)\n",
    "        return x"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T22:33:53.379762Z",
     "start_time": "2024-03-14T22:33:53.343714Z"
    },
    "collapsed": false
   },
   "source": [
    "from kooplearn.models import DynamicAE\n",
    "from lightning.pytorch.callbacks import LearningRateFinder\n",
    "lr_finder = LearningRateFinder(min_lr=1e-6, max_lr=1e-2, early_stop_threshold=None)\n",
    "\n",
    "trainer_kwargs = {\n",
    "    'accelerator': device,\n",
    "    'devices': 1,\n",
    "    'max_epochs':  configs.max_epochs,  \n",
    "    'log_every_n_steps': 3,\n",
    "}\n",
    "trainer = lightning.Trainer(**trainer_kwargs)\n",
    "\n",
    "dae = DynamicAE(\n",
    "    encoder=CNNEncoder,\n",
    "    decoder=CNNDecoder,\n",
    "    latent_dim=configs.classes,\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_kwargs={'lr': 9e-4},\n",
    "    trainer=trainer,\n",
    "    loss_weights= {\"rec\": 1.0, \"pred\": 1.0, \"lin\": 1.0},\n",
    "    encoder_kwargs={'num_classes': configs.classes},\n",
    "    decoder_kwargs={'num_classes': configs.classes},\n",
    "    use_lstsq_for_evolution = False,\n",
    "    seed=configs.rng_seed)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T22:33:59.413982Z",
     "start_time": "2024-03-14T22:33:53.380642Z"
    },
    "collapsed": false
   },
   "source": [
    "dae.fit(train_dataloaders=train_dl)\n",
    "transfer_operator_models[\"Dynamic_AE\"] = dae"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Consistent AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T22:33:59.452600Z",
     "start_time": "2024-03-14T22:33:59.414900Z"
    },
    "collapsed": false
   },
   "source": [
    "from kooplearn.models import ConsistentAE\n",
    "\n",
    "trainer_kwargs = {\n",
    "    'accelerator': device,\n",
    "    'devices': 1,\n",
    "    'max_epochs': configs.max_epochs,  \n",
    "    'log_every_n_steps': 3,\n",
    "}\n",
    "trainer = lightning.Trainer(**trainer_kwargs)\n",
    "\n",
    "cae = ConsistentAE(\n",
    "    encoder=CNNEncoder,\n",
    "    decoder=CNNDecoder,\n",
    "    latent_dim=configs.classes,\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_kwargs={'lr': 9e-4},\n",
    "    trainer=trainer,\n",
    "    loss_weights= {\n",
    "        \"rec\": 1.0,\n",
    "        \"pred\": 1.0,\n",
    "        \"bwd_pred\": 1.0,\n",
    "        \"lin\": 1.0,\n",
    "        \"consistency\": 1.0,\n",
    "    },\n",
    "    encoder_kwargs={'num_classes': configs.classes},\n",
    "    decoder_kwargs={'num_classes': configs.classes},\n",
    "    seed=configs.rng_seed)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T22:34:09.485761Z",
     "start_time": "2024-03-14T22:33:59.453482Z"
    },
    "collapsed": false
   },
   "source": [
    "# We need at least a context_window_len=3 to train the Consistent AutoEncoder\n",
    "train_data = traj_to_contexts(ordered_MNIST['train']['image'], backend='numpy', context_window_len=3)\n",
    "train_dl = DataLoader(train_data, batch_size = configs.batch_size, shuffle=True, collate_fn=collate_context_dataset)\n",
    "\n",
    "cae.fit(train_dataloaders=train_dl)\n",
    "transfer_operator_models[\"Consistent_AE\"] = cae"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final comparison\n",
    "## Model evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T22:34:09.513010Z",
     "start_time": "2024-03-14T22:34:09.486654Z"
    }
   },
   "source": [
    "from kooplearn.abc import BaseModel\n",
    "\n",
    "def evaluate_model(model: BaseModel, test_data):\n",
    "    assert model.is_fitted\n",
    "    report = {\n",
    "        'accuracy': [],\n",
    "        'label': [],\n",
    "        'image': [],\n",
    "        'times': []\n",
    "    }\n",
    "    for t in range(1, configs.eval_up_to_t + 1):\n",
    "        pred = (model.predict(test_data, t=t)).reshape(-1, 28,28) # Shape of the lookforward window\n",
    "        pred_labels = oracle(pred).argmax(axis=1)\n",
    "        accuracy = (pred_labels == (test_labels + t)%configs.classes ).mean()\n",
    "        report['accuracy'].append(accuracy)\n",
    "        report['image'].append(pred)\n",
    "        report['label'].append(pred_labels)\n",
    "        report['times'].append(t)\n",
    "    return report"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T22:34:30.842868Z",
     "start_time": "2024-03-14T22:34:09.513801Z"
    }
   },
   "source": [
    "report = {}\n",
    "for model_name, model in transfer_operator_models.items():\n",
    "        print(f\"Evaluating {model_name.replace('_', ' ')}\")\n",
    "        report[model_name] = evaluate_model(model, test_data)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T22:34:31.037132Z",
     "start_time": "2024-03-14T22:34:30.844063Z"
    }
   },
   "source": [
    "fig, ax = plt.subplots()\n",
    "for model_name in report.keys():\n",
    "    t = report[model_name]['times']\n",
    "    acc = report[model_name]['accuracy']\n",
    "    \n",
    "    ax.plot(t, acc, label=model_name.replace('_', ' '))\n",
    "\n",
    "ax.axhline(1/configs.classes, color='black', linestyle='--', label='Random')\n",
    "\n",
    "ax.legend(frameon=False, bbox_to_anchor=(1, 1))\n",
    "ax.margins(x=0)\n",
    "ax.set_ylim(0, 1.1)\n",
    "ax.set_xlabel('Time steps')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Multistep Accuracy')\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T22:34:41.258303Z",
     "start_time": "2024-03-14T22:34:31.038165Z"
    }
   },
   "source": [
    "n_models = len(report.keys())\n",
    "num_cols = configs.eval_up_to_t + 1\n",
    "fig, axes = plt.subplots(n_models, num_cols, figsize=(num_cols, n_models), sharex=True, sharey=True)\n",
    "\n",
    "test_seed_idx = 0\n",
    "# Remove margins between columns\n",
    "plt.subplots_adjust(wspace=0)\n",
    "\n",
    "for model_idx, model_name in enumerate(report.keys()):\n",
    "    ax = axes[model_idx, 0]\n",
    "    ax.imshow(ordered_MNIST['test']['image'][test_seed_idx], cmap='gray')\n",
    "    # Remove axes and ticks\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.axis('off')\n",
    "    model_eval = report[model_name]\n",
    "\n",
    "    for t_idx in range(num_cols - 1):\n",
    "        pred_label = model_eval['label'][t_idx][test_seed_idx]\n",
    "        true_label = (ordered_MNIST['test']['label'][test_seed_idx] + model_eval['times'][t_idx])%configs.classes\n",
    "        img = model_eval['image'][t_idx][test_seed_idx]\n",
    "\n",
    "        # Set subplot for the current class\n",
    "        ax = axes[model_idx, t_idx + 1]\n",
    "\n",
    "        # Plot the MNIST image\n",
    "        ax.imshow(img, cmap='gray')\n",
    "\n",
    "        # Remove axes and ticks\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.axis('off')\n",
    "\n",
    "        # Add a white background for the subplot\n",
    "        ax.set_facecolor('white')\n",
    "\n",
    "        # Add an inset for the predicted label in the upper right corner\n",
    "        if pred_label == true_label:\n",
    "            color = 'green'\n",
    "        else:\n",
    "            color = 'red'\n",
    "        inset_ax = ax.inset_axes([0.75, 0.75, 0.25, 0.25])\n",
    "        inset_ax.set_xlim(0, 1)\n",
    "        inset_ax.set_ylim(0, 1)\n",
    "        inset_ax.text(0.5, 0.4, f\"{pred_label}\" , color=color, fontsize=9, ha='center', va='center')\n",
    "        inset_ax.set_xticks([])\n",
    "        inset_ax.set_yticks([])\n",
    "        inset_ax.set_facecolor('white')\n",
    "\n",
    "# Display the model names on the left of each row\n",
    "for model_idx, model_name in enumerate(report.keys()):\n",
    "    axes[model_idx, 0].text(-0.1, 0.5, model_name.replace('_', ' '), fontsize=14, ha='right', va='center', transform=axes[model_idx, 0].transAxes)\n",
    "\n",
    "for class_idx in range(num_cols):\n",
    "    title = (ordered_MNIST['test']['label'][test_seed_idx] + class_idx)%configs.classes\n",
    "    if class_idx == 0:\n",
    "        axes[0, class_idx].set_title(f\"Seed: {title}\", fontsize=14)\n",
    "    else:\n",
    "        axes[0, class_idx].set_title(f\"{title}\", fontsize=14)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T22:34:42.957675Z",
     "start_time": "2024-03-14T22:34:41.259330Z"
    }
   },
   "source": [
    "from kooplearn.utils import topk\n",
    "\n",
    "n_models = len(report.keys())\n",
    "num_rows, num_cols = 2, 4\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 8))\n",
    "axes = axes.flatten()\n",
    "for model_idx, model_name in enumerate(report.keys()):\n",
    "    ax = axes[model_idx]\n",
    "    ax.title.set_text(model_name.replace('_', ' '))\n",
    "    fitted_model = transfer_operator_models[model_name]\n",
    "    vals, lfuncs, rfuncs = fitted_model.eig(eval_right_on=test_data, eval_left_on=test_data)\n",
    "    \n",
    "    unique_vals, idx_start = np.unique(np.abs(vals), return_index=True) # returns the unique values and the index of the first occurrence of a value\n",
    "    \n",
    "    vals, lfuncs, rfuncs = vals[idx_start], lfuncs[:, idx_start], rfuncs[:, idx_start]\n",
    "    top_vals = topk(np.abs(vals), 2)\n",
    "    idx_i = top_vals.indices[0]\n",
    "    idx_j = top_vals.indices[1]\n",
    "    \n",
    "    fns = lfuncs\n",
    "    fn_i = fns[:, idx_i].real\n",
    "    fn_j = fns[:, idx_j].real\n",
    "    \n",
    "    scatter = ax.scatter(fn_i, fn_j, c=test_labels, cmap='tab10', vmax=10, alpha=0.7, linewidths=0)\n",
    "    \n",
    "# remove last axis and add legend\n",
    "ax = axes[n_models-1]\n",
    "legend = ax.legend(*scatter.legend_elements(num=4),\n",
    "                    title=\"Digits\", frameon=True, bbox_to_anchor=(1.3, 1))\n",
    "ax.add_artist(legend)\n",
    "fig.delaxes(axes[n_models])\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T22:34:54.640592Z",
     "start_time": "2024-03-14T22:34:42.958794Z"
    }
   },
   "source": [
    "from sklearn.manifold import TSNE\n",
    "DimReduction = TSNE\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 8))\n",
    "axes = axes.flatten()\n",
    "for model_idx, model_name in enumerate(report.keys()):\n",
    "    ax = axes[model_idx]\n",
    "    ax.title.set_text(model_name.replace('_', ' '))\n",
    "    fitted_model = transfer_operator_models[model_name]\n",
    "    vals, lfuncs, rfuncs = fitted_model.eig(eval_right_on=test_data, eval_left_on=test_data)\n",
    "    \n",
    "    # returns the unique values and the index of the first occurrence of a value\n",
    "    unique_vals, idx_start = np.unique(np.abs(vals), return_index=True) \n",
    "    \n",
    "    vals, lfuncs, rfuncs = vals[idx_start], lfuncs[:, idx_start], rfuncs[:, idx_start]\n",
    "    \n",
    "    fns = lfuncs\n",
    "    fns = np.column_stack([lfuncs, rfuncs])\n",
    "    reduced_fns = DimReduction(n_components=2, random_state=42).fit_transform(fns.real)    \n",
    "    fn_i = reduced_fns[:, 0]\n",
    "    fn_j = reduced_fns[:, 1]\n",
    "    \n",
    "    scatter = ax.scatter(fn_i, fn_j, c=test_labels, cmap='tab10', vmax=10, alpha=0.7, linewidths=0)\n",
    "\n",
    "# remove last axis and add legend\n",
    "ax = axes[n_models-1]\n",
    "legend = ax.legend(*scatter.legend_elements(num=4),\n",
    "                    title=\"Digits\", frameon=True, bbox_to_anchor=(1.3, 1))\n",
    "ax.add_artist(legend)\n",
    "fig.delaxes(axes[n_models])\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kooplearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
